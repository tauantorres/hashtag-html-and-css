# Label Studio:
1. [Slide 6] Visto que o label studio é usado para classificar algo em uma imagem complexa (varias coisa dentro dela),
    como seria feito no caso de uma imagem de uma pagina de uma documento, visto que, por exemplo, a sentenca
    poderia ter "3 paginas", porém a última página contem apenas o final do texto sem muito conteúdo ou demonstrativo
    de que de fato aquele trecho pertenca a uma sentaca. Como classificar nesses casos? 

2. Usando o modelo apresentado onde vamos de PDF para img:
    2.1. [Slide 4] Para documentos grandes (2k ou mais) esse processo pode ser muito demorado e custoso. Alguma sugestao 
    de como atuar nesses cenarios? (Paralelizacao?)
    2.2. [Slide 4] Caso manter o tracking de qual pagina esta sendo processado em caso de uma paralelizacao do processo '2.1.'?
    2.3. [Slide 7] O documento apresenta 636 paginas e há classe para 43 delas. Voces querem dizer 43 paginas apresentam 43 classes diferentes?
        Voces consideram casos em que uma classe ( um tipo de documento) possa ter mais de 1 paginas, logo mais paginas estariam sendo classificadas? 

# Multimodal NLP Classification Model:

1. [Slide 10] Nao ficou muito claro o passo-a-passo apresentado. Quais imagens sao carregadas?
    pelo desenho apresentado anteriormento o pdf seria quebrado em paginas individuais, e cada pagina
    convertida em jpeg respectivamente. Sendo assim nao fica muito claro que imagens sao carregas do bucket.
2. [Slide 10] Ainda nas etapas, porque ha uma rotacao da imagem? Algum motivo em especial? Todas as paginas sao rotacionadas?

3. [Slide 10] Na ultima reuniao foi comentado que a extracao é feita via tesseract nos casos que ha necessidade de OCR.
    3.1. Vocês fazem OCR em todas as páginas ou apenas as páginas que precisam de OCR?
    3.2. Caso vocês apliquem OCR apenas nas páginas que precisam:
        3.2.1. De que forma voces verificam quais paginas precisam e quais nao precisam?
        3.2.2. Para a extracao de texto de PDFs nativos o que voces usam?
        3.2.3. Para paginas que precisam de OCR há muitos casos em que o documento foi escaneado torto, nesses casos,
                há a necessidade de rotacioar a imagem de forma a verticalizar o texto antes de extrair a imagem. 
                Como foi estao fazendo isso? Qual abordagem é usada para entender para qual lado rotacior e em quantos graus?
    3.3. Em relacao a tokenizao:
        3.3.1 Poderiam explicar porque decidiram tokenizar o texto? 
        3.3.2 Qual tipo de tokenizao foi usado e porque?   
    
    3.4. Em relacao a lematicazao:
        3.4.1 Porque escolherem lematizar o texto e nao usar steaming, visto que lematizacao é usado mais em analise de sentimentos
            enquanto steaming em classificacao? 

    3.5. Correcao ortografica:
        3.5.1. Depois de aplicar todos os metodos acima citados, porque ainda aplicar uma correcao ortografica?
                Dado o fato que ao somar todos as etapas anteriores ainda fica algo para ser corrigido? 

# Image Classification Model

1. [Slide 14] Em relacao a arquitetura:
    1.1. Algum motivo especial para a escolha dessa arquitetura?
    1.2. Voces testaram outra arquitetura para comparar? 
    1.3. Voces poderiam explicar as camadas do modelo? O que cada uma delas representa? 

2. [Slide 15] Em relacao aos resultados:
    2.1. Como voces conseguiram uma precision de 100%? Isso nao seria um overfiting? 
    2.2. Quantos dados foram usados para treinar? Quantos dados foram usados para validar o modelo?
    2.3. Como foi dividido os dados entre treinamento, validacao e teste?
    2.4. Qual eram as proporcoes do tipos de documentos dentro do documento total? 
        Visto que a 'Decisao Homologacao Calculos' apresentou 0, nao haveria um desbalanceamento entre as classes
    2.5. Houve alguma outra forma de validacao cruzada?
    2.6. Como voces interpretam essa alta precisao alcancada em algumas classes? 
    2.7. Há alguma medida de incerteza ou confianca nas previsoes do modelo?


Referencias:

1. https://www.linkedin.com/pulse/t%C3%A9cnicas-de-pr%C3%A9-processamento-texto-mais-populares-gilson-castro/
2. https://medium.com/@dublado/entendendo-a-tokeniza%C3%A7%C3%A3o-em-modelos-de-linguagem-chatgpt-132b6d9877cb
3. https://colab.research.google.com/drive/1YKwi1PTGU0neD-Pc_g4SQ6QWIWulGm35?usp=sharing
4. https://www.datacamp.com/pt/blog/what-is-tokenization
5. https://datascience.stackexchange.com/questions/44124/when-to-use-dense-conv1-2d-dropout-flatten-and-all-the-other-layers


A imagem mostra uma tabela com valores de métricas para avaliação de um modelo de classificação. Os dados são apresentados para cinco categorias diferentes: "Acórdão Mérito", "Certidão Trânsito Julgado Conhecimento", "Decisão Homologação Cálculos", e "Sentença Mérito". As métricas listadas são precisão, recall, pontuação F1 e suporte para cada categoria. Abaixo, há um resumo geral com as médias de precisão, recall e pontuação F1 (macro e ponderada) e a acurácia.

- **Precisão** indica a proporção de identificações positivas que estavam corretas.
- **Recall** refere-se à proporção de casos positivos reais que foram identificados corretamente.
- **F1-score** é a média harmônica entre precisão e recall, útil quando as classes são desbalanceadas.
- **Suporte** indica o número de ocorrências reais de cada classe no conjunto de dados utilizado.

A categoria "Decisão Homologação Cálculos" tem uma pontuação zero em todas as métricas, indicando que o modelo falhou em identificar corretamente qualquer caso dessa classe. Enquanto isso, as outras categorias mostram uma performance melhor, com destaque para "Certidão Trânsito Julgado Conhecimento" que alcançou pontuação perfeita em todas as métricas.

No rodapé da imagem, parece estar uma assinatura ou carimbo (provavelmente relacionado à instituição responsável pela análise ou pela produção do documento), com referência ao "Estado de São Paulo" e "Comarca de Serra da Serra".